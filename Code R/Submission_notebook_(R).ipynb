{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Submission_notebook_(R).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"ir","display_name":"R"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5fHOA8YzJN1F"},"source":["<div style=\"text-align: center\">\n","  <img alt=\"AIcrowd\" src=\"https://gitlab.aicrowd.com/jyotish/pricing-game-notebook-scripts/raw/master/pricing-game-banner.png\">\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"hs6wY5pwLLyr"},"source":["# How to use this notebook üìù\n","\n","1. **Copy the notebook**. This is a shared template and any edits you make here will not be saved. _You should copy it into your own drive folder._ For this, click the \"File\" menu (top-left), then \"Save a Copy in Drive\". You can edit your copy however you like.\n","2. **Link it to your AICrowd account**. In order to submit your code to AICrowd, you need to provide your account's API key (see [_\"Configure static variables\"_](#static-var) for details).\n","3. **Stick to the function definitions**. The submission to AICrowd will look for the pre-defined function names:\n","  - `install_packages`\n","  - `global_imports`\n","  - `fit_model`\n","  - `save_model`\n","  - `load_model`\n","  - `predict_expected_claim`\n","  - `predict_premium`\n","  - `preprocess_X_data`\n","\n","    Anything else you write outside of these functions will not be part of the final submission (including constants and utility functions), so make sure everything is defined within them, except for:"]},{"cell_type":"markdown","metadata":{"id":"PW1MDeDmcK99"},"source":["# Your pricing model üïµÔ∏è\n","\n","In this notebook, you can play with the data, and define and train your pricing model.\n","You can then directly submit it to the AICrowd server, with some magic code at the end.\n","\n","### Baseline logistic regression üí™\n","You can also play with a baseline logistic regression model [implemented here](https://colab.research.google.com/drive/1hbIWxTHri1TP5cffRYzU_z4bQPvKi3FB?usp=sharing). \n"]},{"cell_type":"markdown","metadata":{"id":"Cf5QtzJELOSL"},"source":["# Prepare the notebook üõ†"]},{"cell_type":"code","metadata":{"id":"ljY8PLQspi3L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610486030692,"user_tz":300,"elapsed":10978,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}},"outputId":"e1e9db36-53b8-4af3-ae6f-3ebd8a99157a"},"source":["cat(system('curl -sL https://gitlab.aicrowd.com/jyotish/pricing-game-notebook-scripts/raw/r-functions/r/setup.sh > setup.sh && bash setup.sh', intern=TRUE), sep='\\n')\n","source(\"aicrowd_helpers.R\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["‚öôÔ∏è Installing AIcrowd utilities...\n","‚úÖ Installed AIcrowd utilities\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ScNf-JbfVtf6"},"source":["# Configure static variables üìé\n","\n","<a name=\"static-var\"></a>\n","\n","In order to submit using this notebook, you must visit this URL https://aicrowd.com/participants/me and copy your API key. \n","\n","Then you must set the value of `AICROWD_API_KEY` wuth the value."]},{"cell_type":"code","metadata":{"id":"v-aU1T_9cUN5","executionInfo":{"status":"ok","timestamp":1610486030692,"user_tz":300,"elapsed":10966,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}}},"source":["TRAINING_DATA_PATH = 'training.csv'\n","AICROWD_API_KEY = 'eaab81e0ad4d64a6b0e7ec99a89205f6'  # You can get the key from https://aicrowd.com/participants/me"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BAq7u_3KjmSv"},"source":["# Download dataset files üíæ"]},{"cell_type":"code","metadata":{"id":"HxNxqHFIjpHP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610486049338,"user_tz":300,"elapsed":29606,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}},"outputId":"a8bcf6a8-cbae-46b1-a812-ac7802a389cd"},"source":["# Make sure to offically join the challenge and accept the challenge rules! Otherwise you will not be able to download the data\n","download_aicrowd_dataset(AICROWD_API_KEY) "],"execution_count":7,"outputs":[{"output_type":"stream","text":["üíæ Downloading dataset...\n","\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"izMI_KQ0c1aS"},"source":["# Packages üóÉ\n","\n","Install and require here all the packages you need to define your model. \n","\n","**Note**: Installing packages the first time might take some time."]},{"cell_type":"code","metadata":{"id":"IdRCnCVmcvMh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610486470634,"user_tz":300,"elapsed":450894,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}},"outputId":"ba949aa1-6e47-4c93-f1c6-e8162744ff61"},"source":["install_packages <- function() {\n","   install.packages(\"caret\")\n","   install.packages(\"rpart\")\n","   install.packages(\"tidyverse\")\n","   install.packages(\"xgboost\")\n","   install.packages(\"mlr\")\n","   install.packages(\"stringr\")\n","   install.packages(\"parallel\")\n","   install.packages(\"parallelMap\")\n","   install.packages(\"goftest\")\n","   install.packages(\"tweedie\")\n","}\n","install_packages()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n","(as ‚Äòlib‚Äô is unspecified)\n","\n","also installing the dependencies ‚ÄònumDeriv‚Äô, ‚ÄòSQUAREM‚Äô, ‚Äòlava‚Äô, ‚Äòprodlim‚Äô, ‚Äòiterators‚Äô, ‚Äòdata.table‚Äô, ‚Äògower‚Äô, ‚Äòipred‚Äô, ‚ÄòtimeDate‚Äô, ‚Äòforeach‚Äô, ‚Äòplyr‚Äô, ‚ÄòModelMetrics‚Äô, ‚Äòreshape2‚Äô, ‚Äòrecipes‚Äô, ‚ÄòpROC‚Äô\n","\n","\n","Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n","(as ‚Äòlib‚Äô is unspecified)\n","\n","Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n","(as ‚Äòlib‚Äô is unspecified)\n","\n","Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n","(as ‚Äòlib‚Äô is unspecified)\n","\n","Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n","(as ‚Äòlib‚Äô is unspecified)\n","\n","also installing the dependencies ‚Äòfastmatch‚Äô, ‚ÄòParamHelpers‚Äô, ‚ÄòBBmisc‚Äô, ‚Äòcheckmate‚Äô, ‚ÄòparallelMap‚Äô, ‚ÄòXML‚Äô\n","\n","\n","Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n","(as ‚Äòlib‚Äô is unspecified)\n","\n","Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n","(as ‚Äòlib‚Äô is unspecified)\n","\n","Warning message:\n","‚Äúpackage ‚Äòparallel‚Äô is a base package, and should not be updated‚Äù\n","Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n","(as ‚Äòlib‚Äô is unspecified)\n","\n","Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n","(as ‚Äòlib‚Äô is unspecified)\n","\n","Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n","(as ‚Äòlib‚Äô is unspecified)\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"kGNATcJ5dK_G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610486474298,"user_tz":300,"elapsed":454550,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}},"outputId":"a001120a-55bf-49e2-eae2-09b5668d9e5a"},"source":["global_imports <- function() {\n","   require(\"caret\")\n","   require(\"rpart\")\n","   require(\"tidyverse\")\n","   require(\"xgboost\")\n","   require(\"mlr\")\n","   require(\"stringr\")\n","   require(\"parallel\")\n","   require(\"parallelMap\")\n","   require(\"goftest\")\n","   require(\"tweedie\")\n","}\n","global_imports()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Loading required package: caret\n","\n","Loading required package: lattice\n","\n","Loading required package: ggplot2\n","\n","Loading required package: rpart\n","\n","Loading required package: tidyverse\n","\n","‚îÄ‚îÄ \u001b[1mAttaching packages\u001b[22m ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.0 ‚îÄ‚îÄ\n","\n","\u001b[32m‚úî\u001b[39m \u001b[34mtibble \u001b[39m 3.0.4     \u001b[32m‚úî\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n","\u001b[32m‚úî\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.2     \u001b[32m‚úî\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n","\u001b[32m‚úî\u001b[39m \u001b[34mreadr  \u001b[39m 1.4.0     \u001b[32m‚úî\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n","\u001b[32m‚úî\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4     \n","\n","‚îÄ‚îÄ \u001b[1mConflicts\u001b[22m ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n","\u001b[31m‚úñ\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n","\u001b[31m‚úñ\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n","\u001b[31m‚úñ\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mlift()\u001b[39m   masks \u001b[34mcaret\u001b[39m::lift()\n","\n","Loading required package: xgboost\n","\n","\n","Attaching package: ‚Äòxgboost‚Äô\n","\n","\n","The following object is masked from ‚Äòpackage:dplyr‚Äô:\n","\n","    slice\n","\n","\n","Loading required package: mlr\n","\n","Loading required package: ParamHelpers\n","\n","'mlr' is in maintenance mode since July 2019. Future development\n","efforts will go into its successor 'mlr3' (<https://mlr3.mlr-org.com>).\n","\n","\n","Attaching package: ‚Äòmlr‚Äô\n","\n","\n","The following object is masked from ‚Äòpackage:caret‚Äô:\n","\n","    train\n","\n","\n","Loading required package: parallel\n","\n","Loading required package: parallelMap\n","\n","Loading required package: goftest\n","\n","Loading required package: tweedie\n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"oIILubWJdVE6"},"source":["# Loading the data üì≤"]},{"cell_type":"code","metadata":{"id":"Hb70XooadS8x","executionInfo":{"status":"ok","timestamp":1610486477636,"user_tz":300,"elapsed":457882,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}}},"source":["# Load the dataset.\n","train_data = read.csv(TRAINING_DATA_PATH)\n","\n","# Create a model, train it, then save it.\n","Xdata = within(train_data, rm('claim_amount'))\n","ydata = train_data['claim_amount']"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GFblo2hHV9L5"},"source":["## How does the data look like? üîç"]},{"cell_type":"code","metadata":{"id":"zRsLgulNV-R1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610486477637,"user_tz":300,"elapsed":457877,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}},"outputId":"f2f82c3b-dda9-431a-d9cb-a6580c6a5322"},"source":["glimpse(train_data)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Rows: 228,216\n","Columns: 26\n","$ id_policy              \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"PL000000\", \"PL042495\", \"PL042496\", \"PL042497\"‚Ä¶\n","$ year                   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n","$ pol_no_claims_discount \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0.332, 0.000, 0.196, 0.000, 0.000, 0.000, 0.01‚Ä¶\n","$ pol_coverage           \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Med2\", \"Med2\", \"Med1\", \"Med2\", \"Med1\", \"Med2\"‚Ä¶\n","$ pol_duration           \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 5, 6, 2, 8, 2, 8, 1, 4, 1, 6, 29, 6, 2, 14, 5,‚Ä¶\n","$ pol_sit_duration       \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 1, 1, 1, 5, 2, 2, 1, 2, 1, 3, 1, 3, 2, 1, 2, 3‚Ä¶\n","$ pol_pay_freq           \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Monthly\", \"Monthly\", \"Yearly\", \"Yearly\", \"Yea‚Ä¶\n","$ pol_payd               \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No‚Ä¶\n","$ pol_usage              \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"WorkPrivate\", \"WorkPrivate\", \"Retired\", \"Work‚Ä¶\n","$ drv_sex1               \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"M\", \"M\", \"M\", \"F\", \"F\", \"F\", \"M\", \"F\", \"M\", \"‚Ä¶\n","$ drv_age1               \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 35, 60, 55, 54, 65, 68, 41, 51, 44, 53, 55, 52‚Ä¶\n","$ drv_age_lic1           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 16, 41, 35, 31, 38, 46, 20, 7, 22, 34, 34, 32,‚Ä¶\n","$ drv_drv2               \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"N‚Ä¶\n","$ drv_sex2               \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"F\", \"0\", \"F\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"‚Ä¶\n","$ drv_age2               \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 26, NA, 57, NA, NA, NA, NA, NA, NA, NA, NA, NA‚Ä¶\n","$ drv_age_lic2           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1, NA, 38, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n","$ vh_make_model          \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"aparvvfowrjncdhp\", \"aparvvfowrjncdhp\", \"iwhqp‚Ä¶\n","$ vh_age                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 8, 10, 8, 4, 13, 16, 1, 28, 12, 14, 15, 12, 15‚Ä¶\n","$ vh_fuel                \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Gasoline\", \"Diesel\", \"Diesel\", \"Gasoline\", \"G‚Ä¶\n","$ vh_type                \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Tourism\", \"Tourism\", \"Commercial\", \"Tourism\",‚Ä¶\n","$ vh_speed               \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 174, 174, 150, 149, 200, 196, 160, 173, 149, 1‚Ä¶\n","$ vh_value               \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 11040, 11040, 14159, 17233, 19422, 24750, 1524‚Ä¶\n","$ vh_weight              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1143, 1143, 1193, 1012, 1315, 1200, 1019, 1112‚Ä¶\n","$ population             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1270, 1290, 1020, 180, 30, 210, 550, 1760, 140‚Ä¶\n","$ town_surface_area      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 33.1, 51.3, 262.8, 219.7, 70.3, 366.5, 74.0, 1‚Ä¶\n","$ claim_amount           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00‚Ä¶\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xGNmm0qPWEjl","colab":{"base_uri":"https://localhost:8080/","height":152},"executionInfo":{"status":"ok","timestamp":1610486477637,"user_tz":300,"elapsed":457871,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}},"outputId":"430b9c3d-ae16-459d-c29b-cddabc2833a2"},"source":["as.matrix(head(ydata, 4))"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["  claim_amount\n","1 0           \n","2 0           \n","3 0           \n","4 0           "],"text/latex":"A matrix: 4 √ó 1 of type dbl\n\\begin{tabular}{r|l}\n  & claim\\_amount\\\\\n\\hline\n\t1 & 0\\\\\n\t2 & 0\\\\\n\t3 & 0\\\\\n\t4 & 0\\\\\n\\end{tabular}\n","text/markdown":"\nA matrix: 4 √ó 1 of type dbl\n\n| <!--/--> | claim_amount |\n|---|---|\n| 1 | 0 |\n| 2 | 0 |\n| 3 | 0 |\n| 4 | 0 |\n\n","text/html":["<table>\n","<caption>A matrix: 4 √ó 1 of type dbl</caption>\n","<thead>\n","\t<tr><th></th><th scope=col>claim_amount</th></tr>\n","</thead>\n","<tbody>\n","\t<tr><th scope=row>1</th><td>0</td></tr>\n","\t<tr><th scope=row>2</th><td>0</td></tr>\n","\t<tr><th scope=row>3</th><td>0</td></tr>\n","\t<tr><th scope=row>4</th><td>0</td></tr>\n","</tbody>\n","</table>\n"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Dk10h86sddEq"},"source":["# Training the model üöÄ\n","\n","You must first define your first function: `fit_model`. This function takes training data as arguments, and outputs a \"model\" object -- that you define as you wish. For instance, this could be an array of parameter values. \n","\n","You may want to define the function `preprocess_X_data` that prepares and cleans your predictor variables for the training and prediction. "]},{"cell_type":"markdown","metadata":{"id":"cJ1OmtTDk6zm"},"source":["## Define your data preprocessing\n","\n","You can add any class or function in this cell for preprocessing. Just make sure that you use the functions here in the `fit_model`, `predict_expected_claim` and `predict_premium` functions if necessary. \n"]},{"cell_type":"code","metadata":{"id":"nigHdUYck_6s","executionInfo":{"status":"ok","timestamp":1610486477638,"user_tz":300,"elapsed":457865,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}}},"source":["preprocess_X_data <- function (x_raw){\n","   #' Data preprocessing function: given X_raw, clean the data for training or \n","   #' prediction.\n","   #'\n","   #' Parameters\n","   #' ----------\n","   #' @X_raw : Dataframe, with the columns described in the data dictionary.\n","   #' \tEach row is a different contract. This data has not been processed.\n","   #'\n","   #' Returns\n","   #' -------\n","   #' A cleaned / preprocessed version of the dataset\n","      \n","   Compress_vh_make_model <- function(x_raw, years=c(1)) {\n","      #' Keeps only the vehicul models the most relevants\n","      #' for regression.\n","      freq_tbl <- x_raw %>%\n","         select(vh_make_model, year) %>%\n","         filter(year %in% years) %>%\n","         table() %>% as.data.frame()\n","      \n","      n_labels <- nrow(freq_tbl)\n","      \n","      labels_to_concat <- freq_tbl[which(freq_tbl[, 'Freq'] < 30), 1]\n","      \n","      x_raw[x_raw[,\"vh_make_model\"] %in% labels_to_concat, \"vh_make_model\"] <- \n","         'others'\n","\n","      return(x_raw)\n","   }\n","   \n","   feature_ingeneering <- function(x_raw) {\n","      x_raw <- Compress_vh_make_model(x_raw)\n","      x_raw <- x_raw %>% mutate(\n","         id_policy = NULL,\n","         across(where(is.character), str_to_lower),\n","         pop_density = population / town_surface_area,\n","         vh_speed_drv_age_ratio = vh_speed / drv_age1,\n","         potential_force_impact = vh_speed * vh_weight,\n","         pol_pay_freq = NULL\n","      )\n","      return(x_raw)\n","   }\n","   \n","   # Add and transform some features\n","   x_preprocessed <- feature_ingeneering(x_raw)\n","   \n","   # Impute missing values\n","   imputation <- x_preprocessed %>%\n","      filter(year==1) %>%\n","      impute(\n","         classes = list(numeric = imputeMean()),\n","         dummy.cols = 'vh_value'\n","      )\n","   x_preprocessed <- x_preprocessed %>%\n","         reimpute(imputation$desc)\n","   \n","   # One-Hot-Encoding\n","   x_preprocessed <- model.matrix( ~ . + 0, data = x_preprocessed) %>%\n","      as.data.frame() %>%\n","      mutate(vh_value_dummyTRUE = vh_value.dummyTRUE) %>%\n","      select(-vh_value.dummyTRUE)\n","    \n","   return(x_preprocessed)\n","}"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UT_jJRFPkx7O"},"source":["## Define the training logic"]},{"cell_type":"code","metadata":{"id":"bcKm2Av9daqY","executionInfo":{"status":"ok","timestamp":1610486477639,"user_tz":300,"elapsed":457860,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}}},"source":["fit_model <- function (x_raw, y_raw){\n","   #' Model training function: given training data (X_raw, y_raw), train this\n","   #' pricing model.\n","   #'\n","   #' Parameters\n","   #' ----------\n","   #' @X_raw : Dataframe, with the columns described in the data dictionary.\n","   #' \tEach row is a different contract. This data has not been processed.\n","   #' @y_raw : An array, with the value of the claims, in the same order as \n","   #'    contracts in X_raw. A one dimensional array, with values either 0 \n","   #'    (most entries) or >0.\n","   #'\n","   #' Returns\n","   #' -------\n","   #' self: (optional), this instance of the fitted model.\n","   \n","   TRAINING_YEARS <-  c(1,2,3,4)\n","   VALIDATION_YEARS <- c(4)\n","   GRIDSEARCH <- FALSE\n","   EVALUATE_MODEL <- FALSE\n","   \n","   x_raw <- Xdata\n","   y_raw <- ydata\n","   \n","   x_clean  <- preprocess_X_data(x_raw)\n","   df <- data.frame(y_raw, x_clean)\n","   \n","   df_valid <- df %>% filter(year %in% VALIDATION_YEARS) %>% select(-c(year))\n","   df_train <- df %>% filter(year %in% TRAINING_YEARS) %>% select(-c(year))\n","   \n","   # Training an occurrence detection model with XGB\n","   train_xgb_occurrence <- \n","      function(df_train, df_valid, gridsearch=F, evaluate_perf=T){\n","         #' Function to train a XGBoost with an objective of type \n","         #' binary:logistic for occurrence detection.\n","         #' \n","         #' Parameters\n","         #' ----------\n","         #' @df_train dataframe containing training data\n","         #' @df_valid dataframe containing valitation data\n","         #' @gridsearch Boolean: Use Gridsearch to optimize hyperparameters ?\n","         #' @evaluate_perf Boolean: Use df_valid to calculate ROC AUC on \n","         #' predictions\n","         #' \n","         #' returns\n","         #' -------\n","         #' @model trained model\n","         #' @auc Calculated ROC AUC on the validation data.\n","         \n","         # Rebalancing the classes for the training set\n","         resample <- function(df, strategy=list('under'=0.7, 'over'=1.2)) {\n","            \n","            random_undersample <- function(df, size){\n","               df0 <- df %>% filter(occ == F) %>%\n","                  slice_sample(n=size, replace=FALSE)\n","               df1 <- df %>% filter(occ == T)\n","               return(rbind(df0, df1))\n","            }\n","            \n","            random_oversample <- function(df, size){\n","               df0 <- df %>% filter(occ == F) \n","               df1 <- df %>% filter(occ == T) %>%\n","                  slice_sample(n=size, replace=TRUE)\n","               return(rbind(df0, df1))\n","            }\n","               \n","            dim_classes <- df %>% select(occ) %>% table()\n","            dim_classes <- dim_classes * c(strategy$under, strategy$over)\n","            \n","            df <- random_oversample(df, dim_classes[2])\n","            df <- random_undersample(df, dim_classes[1])\n","            return(df)\n","         }\n","         \n","         \n","         df_train_occ <- df_train %>%\n","            mutate(occ = factor(claim_amount>0)) %>%\n","            select(-claim_amount) %>% \n","            resample()\n","            \n","         # Preparing a validation dataset\n","         df_valid_occ <- df_valid %>%\n","            mutate(occ = factor(claim_amount>0)) %>%\n","            select(-claim_amount)\n","      \n","         # Defining task and learner for the mlr optimizer\n","         train_task <- makeClassifTask(\n","            data = df_train_occ, target = \"occ\", positive = \"FALSE\")\n","         valid_task <- makeClassifTask(\n","            data = df_valid_occ, target = \"occ\", positive = \"FALSE\")\n","         \n","         learner <- makeLearner(\"classif.xgboost\", predict.type = \"prob\")\n","         \n","         if (gridsearch) {\n","            # Set parallel backend\n","            parallelStartSocket(cpus = detectCores())\n","            \n","            # Model fixed parameters\n","            learner$par.vals <- list(\n","               objective = \"binary:logistic\",\n","               eval_metric = \"auc\",\n","               nrounds = 100\n","            )\n","            \n","            # Set parameter space for gridsearch\n","            params <- makeParamSet(\n","               makeDiscreteParam(\"booster\", values = c(\n","                  'gbtree', 'gblinear', 'dart')),\n","               makeIntegerParam(\"max_depth\", lower = 3L, upper = 6L),\n","               makeNumericParam(\"min_child_weight\", lower = 1L, upper = 10L),\n","               makeNumericParam(\"subsample\", lower = 0.5, upper = 1),\n","               makeNumericParam(\"colsample_bytree\", lower = 0.5, upper = 1),\n","               makeNumericParam(\"lambda\", lower=1, upper=4),\n","               makeNumericParam(\"alpha\", lower=0, upper=3),\n","               makeNumericParam(\"eta\", lower = 0.1, upper = 0.5)\n","            )\n","            \n","            resampling <- makeResampleDesc(\"CV\", stratify = T, iters = 5L)\n","            control <- makeTuneControlRandom(maxit = 10L, tune.threshold=T)\n","            \n","            # Parameter tuning\n","            mytune <- tuneParams(\n","               learner = learner,\n","               task = train_task,\n","               resampling = resampling,\n","               par.set = params,\n","               control = control,\n","               show.info = T\n","            )\n","            parallelStop()\n","            \n","            # Set hyperparameters\n","            learner <- setHyperPars(learner, par.vals = mytune$x)\n","            \n","         } else {\n","            # Pretuned parameters :\n","            # ---------------------\n","            #' [Tune] Result: booster=gbtree; max_depth=6; \n","            #' min_child_weight=2.79; subsample=0.749; colsample_bytree=0.584; \n","            #' lambda=3.93; alpha=0.0535; eta=0.469 : \n","            #' @mmce.test.mean=0.1655115\n","            learner$par.vals <- list(\n","               objective = \"binary:logistic\",\n","               eval_metric = \"auc\",\n","               nrounds = 50,\n","               eta = 0.1,\n","               booster = 'gbtree',\n","               max_depth = 3,\n","               min_child_weight = 2.79,\n","               subsample = 0.749,\n","               colsample_bytree = 0.584,\n","               lambda = 3.93,\n","               alpha = 2\n","            )\n","         }\n","         \n","         # Train model\n","         xgb_model <- mlr::train(learner = learner, task = train_task)\n","         \n","         # Evaluation of performance for the occurrence detection.\n","         if (evaluate_perf){\n","            # Predictions\n","            occ_predictions <- predict(xgb_model, valid_task)\n","            # AUC\n","            occ_auc <- mlr::performance(occ_predictions, mlr::auc)\n","            print(occ_auc, quote=F)\n","            # Confusion matrix\n","            print(mlr::calculateConfusionMatrix(pred = occ_predictions), quote=F)\n","            \n","            return(list(\"model\"=xgb_model, \"auc\"=occ_auc))\n","            }\n","         return(list(\"model\"=xgb_model))\n","   }\n","   \n","   # Training aggregated severity model (XGB: Tweedie model)\n","   train_xgb_tweedie <- \n","      function(df_train, df_valid, gridsearch=F, evaluate_perf=T){\n","         #' Function to train a XGBoost with an objective of type \n","         #' reg:tweedie\n","         #' \n","         #' Parameters\n","         #' ----------\n","         #' @df_train dataframe containing training data\n","         #' @df_valid dataframe containing valitation data\n","         #' @gridsearch Boolean: Use Gridsearch to optimize hyperparameters ?\n","         #' @evaluate_perf Boolean: Use df_valid to calculate RMSE on \n","         #' predictions\n","         #' \n","         #' returns\n","         #' -------\n","         #' @model trained model\n","         #' @rmse Calculated rmse on the validation data.\n","         \n","         df_train_loss <- df_train %>%\n","            filter(claim_amount>0)\n","         \n","         df_valid_loss <- df_valid %>%\n","            filter(claim_amount>0)\n","         \n","         # Defining task and learner for the mlr optimizer\n","         train_task <- makeRegrTask(\n","            data = df_train_loss, \n","            target = \"claim_amount\")\n","         valid_task <- makeRegrTask(\n","            data = df_valid_loss, \n","            target = \"claim_amount\")\n","         \n","         learner <- makeLearner(\"regr.xgboost\", predict.type = \"response\")\n","         \n","         if (gridsearch) {\n","            # Set parallel backend\n","            parallelStartSocket(cpus = detectCores())\n","            \n","            # Model fixed parameters\n","            learner$par.vals <- list(\n","               objective = \"reg:tweedie\",\n","               eval_metric = \"rmse\",\n","               nrounds = 200,\n","               gamma = 1e-1\n","            )\n","            \n","            # Set parameter space for gridsearch\n","            params <- makeParamSet(\n","               makeNumericParam(\"tweedie_variance_power\", lower=1, upper=2),\n","               makeDiscreteParam(\"booster\", values = c(\n","                  'gbtree', 'gblinear', 'dart')),\n","               makeIntegerParam(\"max_depth\", lower = 3L, upper = 6L),\n","               makeNumericParam(\"min_child_weight\", lower = 1L, upper = 10L),\n","               makeNumericParam(\"subsample\", lower = 0.5, upper = 1),\n","               makeNumericParam(\"colsample_bytree\", lower = 0.5, upper = 1),\n","               makeNumericParam(\"lambda\", lower=1, upper=4),\n","               makeNumericParam(\"alpha\", lower=0, upper=3),\n","               makeNumericParam('eta', lower=0.1, upper=0.5)\n","            )\n","            \n","            control <- makeTuneControlRandom(maxit = 10L)\n","            resampling <- makeResampleDesc(\"CV\", iters = 5L)\n","            \n","            # Parameter tuning\n","            mytune <- tuneParams(\n","               learner = learner,\n","               task = train_task,\n","               resampling = resampling,\n","               par.set = params,\n","               control = control,\n","               show.info = T\n","            )\n","            parallelStop()\n","            \n","            # Set hyperparameters\n","            learner <- setHyperPars(learner, par.vals = mytune$x)\n","            \n","         } else {\n","            # Pretuned parameters :\n","            # ---------------------\n","            #' [Tune] Result: tweedie_variance_power=1.12; booster=gblinear;\n","            #' max_depth=4; min_child_weight=7.1; subsample=0.94;\n","            #' colsample_bytree=0.617; lambda=3.11; alpha=0.295; eta=0.314 :\n","            #' @mse.test.mean=3348276.3538605\n","            learner$par.vals <- list(\n","               objective = \"reg:tweedie\",\n","               eval_metric = \"rmse\",\n","               nrounds = 200,\n","               eta = 0.314,\n","               gamma = 1e-1,\n","               tweedie_variance_power=1.12,\n","               booster='gblinear',\n","               max_depth=4,\n","               min_child_weight=7.1,\n","               subsample=0.94,\n","               colsample_bytree=0.617,\n","               lambda=3.11,\n","               alpha=0.295\n","            )\n","         }\n","         \n","         # Train model\n","         xgb_model <- mlr::train(learner = learner, task = train_task)\n","         \n","         if (evaluate_perf){\n","            # Evaluation of performance for the occurrence detection.\n","            claim_predictions <- predict(xgb_model, valid_task)\n","            # RMSE\n","            rmse_tweedie <- mlr::performance(claim_predictions, mlr::rmse)\n","            print(rmse_tweedie)\n","            \n","            # Calculate measures for adequacy evaluation\n","            truth <- claim_predictions$data$truth\n","            mu <- claim_predictions$data$response\n","            xi <- xgb_model$learner.model$params$tweedie_variance_power\n","            phi <- optimize(function(phi) {\n","               -sum(log(1 + dtweedie(\n","                  y = truth,\n","                  xi = xi,\n","                  mu = mu,\n","                  phi = phi\n","               )))\n","            }, interval = c(0.1, 1000))$minimum\n","            U <- ecdf(truth)(truth)\n","            Fx <- function(x) ptweedie(x, xi=xi, mu=mu, phi = phi)\n","            \n","            # Kolmogorov-Smirnov test\n","            ks.test(U, Fx(truth))\n","            \n","            # Anderson-Darling test\n","            goftest::ad.test(truth, null=Fx, estimated=F, nullname = 'Tweedie')\n","            #' According to both the K-S and A-D test, the model doesn't fit \n","            #' well to the dataset. \n","            return(list(\"model\"=xgb_model, \"rmse\"=rmse_tweedie))\n","         }\n","         return(list(\"model\"=xgb_model))\n","   }\n","   \n","   \n","   severity_model <- train_xgb_tweedie(df_train,\n","                                       df_valid,\n","                                       gridsearch = GRIDSEARCH,\n","                                       evaluate_perf = EVALUATE_MODEL)$model\n","   occ_model <- train_xgb_occurrence(df_train, \n","                                     df_valid, \n","                                     gridsearch = GRIDSEARCH,\n","                                     evaluate_perf = EVALUATE_MODEL)$model\n","\n","   return(list(occurence = occ_model,\n","               cost = severity_model))\n","}"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"YVb9Cvbkn-5Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610486577771,"user_tz":300,"elapsed":557986,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}},"outputId":"56a0c171-aae4-4a55-a440-6f8d84c9d930"},"source":["model = fit_model(Xdata, ydata)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[21:21:37] WARNING: amalgamation/../src/learner.cc:541: \n","Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n","\n","  This may not be accurate due to some parameters are only used in language bindings but\n","  passed down to XGBoost core.  Or some parameters are not used but slip through this\n","  verification. Please open an issue if you find above cases.\n","\n","\n","[1]\ttrain-rmse:6363.581055 \n","[2]\ttrain-rmse:3126.052734 \n","[3]\ttrain-rmse:2488.643066 \n","[4]\ttrain-rmse:2335.894531 \n","[5]\ttrain-rmse:2257.385498 \n","[6]\ttrain-rmse:2203.866211 \n","[7]\ttrain-rmse:2164.817139 \n","[8]\ttrain-rmse:2135.197021 \n","[9]\ttrain-rmse:2112.111816 \n","[10]\ttrain-rmse:2093.759766 \n","[11]\ttrain-rmse:2079.039795 \n","[12]\ttrain-rmse:2067.082031 \n","[13]\ttrain-rmse:2057.322266 \n","[14]\ttrain-rmse:2049.261963 \n","[15]\ttrain-rmse:2042.603516 \n","[16]\ttrain-rmse:2037.070312 \n","[17]\ttrain-rmse:2032.441772 \n","[18]\ttrain-rmse:2028.563721 \n","[19]\ttrain-rmse:2025.290771 \n","[20]\ttrain-rmse:2022.516479 \n","[21]\ttrain-rmse:2020.157715 \n","[22]\ttrain-rmse:2018.131714 \n","[23]\ttrain-rmse:2016.394043 \n","[24]\ttrain-rmse:2014.882568 \n","[25]\ttrain-rmse:2013.569702 \n","[26]\ttrain-rmse:2012.416504 \n","[27]\ttrain-rmse:2011.405640 \n","[28]\ttrain-rmse:2010.509521 \n","[29]\ttrain-rmse:2009.712646 \n","[30]\ttrain-rmse:2009.002930 \n","[31]\ttrain-rmse:2008.366089 \n","[32]\ttrain-rmse:2007.789307 \n","[33]\ttrain-rmse:2007.270142 \n","[34]\ttrain-rmse:2006.791626 \n","[35]\ttrain-rmse:2006.364014 \n","[36]\ttrain-rmse:2005.969238 \n","[37]\ttrain-rmse:2005.599854 \n","[38]\ttrain-rmse:2005.261475 \n","[39]\ttrain-rmse:2004.945312 \n","[40]\ttrain-rmse:2004.656616 \n","[41]\ttrain-rmse:2004.384277 \n","[42]\ttrain-rmse:2004.130127 \n","[43]\ttrain-rmse:2003.894775 \n","[44]\ttrain-rmse:2003.671875 \n","[45]\ttrain-rmse:2003.459717 \n","[46]\ttrain-rmse:2003.262329 \n","[47]\ttrain-rmse:2003.075562 \n","[48]\ttrain-rmse:2002.898071 \n","[49]\ttrain-rmse:2002.729248 \n","[50]\ttrain-rmse:2002.571289 \n","[51]\ttrain-rmse:2002.419922 \n","[52]\ttrain-rmse:2002.275024 \n","[53]\ttrain-rmse:2002.139771 \n","[54]\ttrain-rmse:2002.008301 \n","[55]\ttrain-rmse:2001.884521 \n","[56]\ttrain-rmse:2001.764526 \n","[57]\ttrain-rmse:2001.651978 \n","[58]\ttrain-rmse:2001.543213 \n","[59]\ttrain-rmse:2001.436890 \n","[60]\ttrain-rmse:2001.336060 \n","[61]\ttrain-rmse:2001.240234 \n","[62]\ttrain-rmse:2001.145752 \n","[63]\ttrain-rmse:2001.055786 \n","[64]\ttrain-rmse:2000.971069 \n","[65]\ttrain-rmse:2000.885498 \n","[66]\ttrain-rmse:2000.805298 \n","[67]\ttrain-rmse:2000.724731 \n","[68]\ttrain-rmse:2000.648926 \n","[69]\ttrain-rmse:2000.578247 \n","[70]\ttrain-rmse:2000.507324 \n","[71]\ttrain-rmse:2000.438843 \n","[72]\ttrain-rmse:2000.372192 \n","[73]\ttrain-rmse:2000.307617 \n","[74]\ttrain-rmse:2000.245728 \n","[75]\ttrain-rmse:2000.186035 \n","[76]\ttrain-rmse:2000.125977 \n","[77]\ttrain-rmse:2000.069946 \n","[78]\ttrain-rmse:2000.013184 \n","[79]\ttrain-rmse:1999.958984 \n","[80]\ttrain-rmse:1999.905762 \n","[81]\ttrain-rmse:1999.856934 \n","[82]\ttrain-rmse:1999.804810 \n","[83]\ttrain-rmse:1999.757080 \n","[84]\ttrain-rmse:1999.709351 \n","[85]\ttrain-rmse:1999.661621 \n","[86]\ttrain-rmse:1999.618286 \n","[87]\ttrain-rmse:1999.573364 \n","[88]\ttrain-rmse:1999.530151 \n","[89]\ttrain-rmse:1999.487427 \n","[90]\ttrain-rmse:1999.446655 \n","[91]\ttrain-rmse:1999.406616 \n","[92]\ttrain-rmse:1999.367065 \n","[93]\ttrain-rmse:1999.329102 \n","[94]\ttrain-rmse:1999.292236 \n","[95]\ttrain-rmse:1999.255981 \n","[96]\ttrain-rmse:1999.220093 \n","[97]\ttrain-rmse:1999.186279 \n","[98]\ttrain-rmse:1999.149536 \n","[99]\ttrain-rmse:1999.115845 \n","[100]\ttrain-rmse:1999.081421 \n","[101]\ttrain-rmse:1999.050537 \n","[102]\ttrain-rmse:1999.020020 \n","[103]\ttrain-rmse:1998.989014 \n","[104]\ttrain-rmse:1998.956909 \n","[105]\ttrain-rmse:1998.928833 \n","[106]\ttrain-rmse:1998.897827 \n","[107]\ttrain-rmse:1998.868652 \n","[108]\ttrain-rmse:1998.840210 \n","[109]\ttrain-rmse:1998.814819 \n","[110]\ttrain-rmse:1998.784546 \n","[111]\ttrain-rmse:1998.756836 \n","[112]\ttrain-rmse:1998.730103 \n","[113]\ttrain-rmse:1998.703003 \n","[114]\ttrain-rmse:1998.680298 \n","[115]\ttrain-rmse:1998.652588 \n","[116]\ttrain-rmse:1998.630371 \n","[117]\ttrain-rmse:1998.603882 \n","[118]\ttrain-rmse:1998.578979 \n","[119]\ttrain-rmse:1998.556396 \n","[120]\ttrain-rmse:1998.532104 \n","[121]\ttrain-rmse:1998.505615 \n","[122]\ttrain-rmse:1998.484497 \n","[123]\ttrain-rmse:1998.460938 \n","[124]\ttrain-rmse:1998.439087 \n","[125]\ttrain-rmse:1998.414551 \n","[126]\ttrain-rmse:1998.392822 \n","[127]\ttrain-rmse:1998.371582 \n","[128]\ttrain-rmse:1998.348633 \n","[129]\ttrain-rmse:1998.328613 \n","[130]\ttrain-rmse:1998.308716 \n","[131]\ttrain-rmse:1998.287964 \n","[132]\ttrain-rmse:1998.266113 \n","[133]\ttrain-rmse:1998.245361 \n","[134]\ttrain-rmse:1998.226562 \n","[135]\ttrain-rmse:1998.208252 \n","[136]\ttrain-rmse:1998.187988 \n","[137]\ttrain-rmse:1998.168335 \n","[138]\ttrain-rmse:1998.148682 \n","[139]\ttrain-rmse:1998.131348 \n","[140]\ttrain-rmse:1998.111450 \n","[141]\ttrain-rmse:1998.094116 \n","[142]\ttrain-rmse:1998.075806 \n","[143]\ttrain-rmse:1998.057983 \n","[144]\ttrain-rmse:1998.041748 \n","[145]\ttrain-rmse:1998.022705 \n","[146]\ttrain-rmse:1998.005981 \n","[147]\ttrain-rmse:1997.988892 \n","[148]\ttrain-rmse:1997.970459 \n","[149]\ttrain-rmse:1997.953125 \n","[150]\ttrain-rmse:1997.936279 \n","[151]\ttrain-rmse:1997.920288 \n","[152]\ttrain-rmse:1997.902832 \n","[153]\ttrain-rmse:1997.884644 \n","[154]\ttrain-rmse:1997.869019 \n","[155]\ttrain-rmse:1997.853516 \n","[156]\ttrain-rmse:1997.838867 \n","[157]\ttrain-rmse:1997.824097 \n","[158]\ttrain-rmse:1997.806885 \n","[159]\ttrain-rmse:1997.790649 \n","[160]\ttrain-rmse:1997.774414 \n","[161]\ttrain-rmse:1997.759277 \n","[162]\ttrain-rmse:1997.744141 \n","[163]\ttrain-rmse:1997.729126 \n","[164]\ttrain-rmse:1997.712524 \n","[165]\ttrain-rmse:1997.696899 \n","[166]\ttrain-rmse:1997.681763 \n","[167]\ttrain-rmse:1997.666870 \n","[168]\ttrain-rmse:1997.652954 \n","[169]\ttrain-rmse:1997.637451 \n","[170]\ttrain-rmse:1997.622192 \n","[171]\ttrain-rmse:1997.607666 \n","[172]\ttrain-rmse:1997.591919 \n","[173]\ttrain-rmse:1997.579590 \n","[174]\ttrain-rmse:1997.565796 \n","[175]\ttrain-rmse:1997.551758 \n","[176]\ttrain-rmse:1997.536133 \n","[177]\ttrain-rmse:1997.520752 \n","[178]\ttrain-rmse:1997.508667 \n","[179]\ttrain-rmse:1997.495239 \n","[180]\ttrain-rmse:1997.479858 \n","[181]\ttrain-rmse:1997.466187 \n","[182]\ttrain-rmse:1997.452515 \n","[183]\ttrain-rmse:1997.437622 \n","[184]\ttrain-rmse:1997.425903 \n","[185]\ttrain-rmse:1997.411621 \n","[186]\ttrain-rmse:1997.398560 \n","[187]\ttrain-rmse:1997.384644 \n","[188]\ttrain-rmse:1997.370972 \n","[189]\ttrain-rmse:1997.356812 \n","[190]\ttrain-rmse:1997.344116 \n","[191]\ttrain-rmse:1997.329956 \n","[192]\ttrain-rmse:1997.317383 \n","[193]\ttrain-rmse:1997.302246 \n","[194]\ttrain-rmse:1997.288330 \n","[195]\ttrain-rmse:1997.278198 \n","[196]\ttrain-rmse:1997.263306 \n","[197]\ttrain-rmse:1997.250122 \n","[198]\ttrain-rmse:1997.240845 \n","[199]\ttrain-rmse:1997.226074 \n","[200]\ttrain-rmse:1997.213013 \n","[1]\ttrain-auc:0.617207 \n","[2]\ttrain-auc:0.631398 \n","[3]\ttrain-auc:0.633083 \n","[4]\ttrain-auc:0.634270 \n","[5]\ttrain-auc:0.635955 \n","[6]\ttrain-auc:0.635926 \n","[7]\ttrain-auc:0.638278 \n","[8]\ttrain-auc:0.639917 \n","[9]\ttrain-auc:0.640105 \n","[10]\ttrain-auc:0.640838 \n","[11]\ttrain-auc:0.640428 \n","[12]\ttrain-auc:0.640674 \n","[13]\ttrain-auc:0.641643 \n","[14]\ttrain-auc:0.641788 \n","[15]\ttrain-auc:0.641958 \n","[16]\ttrain-auc:0.642429 \n","[17]\ttrain-auc:0.642696 \n","[18]\ttrain-auc:0.643003 \n","[19]\ttrain-auc:0.643434 \n","[20]\ttrain-auc:0.643853 \n","[21]\ttrain-auc:0.644311 \n","[22]\ttrain-auc:0.644533 \n","[23]\ttrain-auc:0.644603 \n","[24]\ttrain-auc:0.644548 \n","[25]\ttrain-auc:0.644840 \n","[26]\ttrain-auc:0.645145 \n","[27]\ttrain-auc:0.645513 \n","[28]\ttrain-auc:0.645892 \n","[29]\ttrain-auc:0.645904 \n","[30]\ttrain-auc:0.646055 \n","[31]\ttrain-auc:0.646422 \n","[32]\ttrain-auc:0.646580 \n","[33]\ttrain-auc:0.647017 \n","[34]\ttrain-auc:0.647254 \n","[35]\ttrain-auc:0.647510 \n","[36]\ttrain-auc:0.647737 \n","[37]\ttrain-auc:0.647814 \n","[38]\ttrain-auc:0.647883 \n","[39]\ttrain-auc:0.648000 \n","[40]\ttrain-auc:0.648306 \n","[41]\ttrain-auc:0.648366 \n","[42]\ttrain-auc:0.648539 \n","[43]\ttrain-auc:0.648663 \n","[44]\ttrain-auc:0.648723 \n","[45]\ttrain-auc:0.649015 \n","[46]\ttrain-auc:0.649287 \n","[47]\ttrain-auc:0.649547 \n","[48]\ttrain-auc:0.649761 \n","[49]\ttrain-auc:0.649981 \n","[50]\ttrain-auc:0.650109 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KOKTwZGPb-w2"},"source":["## Saving your model\n","\n","You can save your model to a file here, so you don't need to retrain it every time."]},{"cell_type":"code","metadata":{"id":"8kMfPJKlb-w2","executionInfo":{"status":"ok","timestamp":1610486577771,"user_tz":300,"elapsed":557978,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}}},"source":["save_model <- function(model){\n","  # Saves this trained model to a file.\n","\n","  # This is used to save the model after training, so that it can be used for prediction later.\n","\n","  # Do not touch this unless necessary (if you need specific features). If you do, do not\n","  #  forget to update the load_model method to be compatible.\n","\t\n","  # The default is to save it in 'trained_model.RData', but change this if you \n","  # are using a pacakge that requires a different saving format.\n","  # For h2o models see this discussion: https://discourse.aicrowd.com/t/any-tips-for-successfully-submitting-an-h2o-model/4194/\n","\n","  save(model, file='trained_model.RData')\n","}\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"fNMwNh_jt1uz","executionInfo":{"status":"ok","timestamp":1610486577772,"user_tz":300,"elapsed":557972,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}}},"source":["save_model(model)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vnZIECd4b-w2"},"source":["If you need to load it from file, you can use this code:"]},{"cell_type":"code","metadata":{"id":"z03gpfMEb-w2","executionInfo":{"status":"ok","timestamp":1610486577772,"user_tz":300,"elapsed":557963,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}}},"source":["load_model <- function(){ \n"," # Load a saved trained model from the file `trained_model.RData`.\n"," # This is called by the server to evaluate your submission on hidden data.\n","\n","\n"," # Only modify this *if* you modified save_model.\n","\n","  load('trained_model.RData')\n","  return(model)\n","}"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xjEHnWut6Tm","executionInfo":{"status":"ok","timestamp":1610486577773,"user_tz":300,"elapsed":557956,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}}},"source":["model = load_model()"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OQGzojS_b-w3"},"source":["# Predicting the claims üíµ\n","\n","The second function, `predict_expected_claim`, takes your trained model and a dataframe of contracts, and outputs a prediction for the (expected) claim incurred by each contract. This expected claim can be seen as the probability of an accident multiplied by the cost of that accident.\n","\n","This is the function used to compute the _RMSE_ leaderboard, where the model best able to predict claims wins."]},{"cell_type":"code","metadata":{"id":"t4X3CPaZb-w3","executionInfo":{"status":"ok","timestamp":1610486577773,"user_tz":300,"elapsed":557950,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}}},"source":["predict_expected_claim <- function(model, x_raw){\n","   #' Model prediction function: predicts the average claim based on the pricing model.\n","   #'\n","   #' This functions estimates the expected claim made by a contract (typically, as the product\n","   #' of the probability of having a claim multiplied by the average cost of a claim if it occurs),\n","   #' for each contract in the dataset X_raw.\n","   #'   \n","   #' This is the function used in the RMSE leaderboard, and hence the output should be as close\n","   #' as possible to the expected cost of a contract.\n","   #'\n","   #' Parameters\n","   #' ----------\n","   #' @X_raw : Dataframe, with the columns described in the data dictionary.\n","   #' \tEach row is a different contract. This data has not been processed.\n","   #'\n","   #' Returns\n","   #' -------\n","   #' @avg_claims: a one-dimensional array of the same length as X_raw, with one\n","   #'     average claim per contract (in same order). These average claims must be POSITIVE (>0).\n","   \n","   x_clean = preprocess_X_data(x_raw) %>% select(-year)\n","   \n","   expected_occ <- predict(model$occurence, newdata = x_clean)$data$prob.TRUE\n","   expected_loss <- predict(model$cost, newdata = x_clean)$data$response\n","   \n","   expected_claims = expected_occ * expected_loss\n","   return(round(expected_claims, 2))  \n","}"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"nqOw2Xbj0i9S","executionInfo":{"status":"ok","timestamp":1610486599957,"user_tz":300,"elapsed":580128,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}}},"source":["claims <- predict_expected_claim(model, Xdata)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LcQe1oASb-w3"},"source":["# Pricing contracts üí∞\n","\n","The third and final function, `predict_premium`, takes your trained model and a dataframe of contracts, and outputs a _price_ for each of these contracts. **You are free to set this prices however you want!** These prices will then be used in competition with other models: contracts will choose the model offering the lowest price, and this model will have to pay the cost if an accident occurs.\n","\n","This is the function used to compute the _profit_ leaderboard: your model will participate in many markets of size 10, populated by other participants' model, and we compute the average profit of your model over all the markets it participated in."]},{"cell_type":"code","metadata":{"id":"qT3c8nuWb-w3","executionInfo":{"status":"ok","timestamp":1610486599959,"user_tz":300,"elapsed":580124,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}}},"source":["predict_premium <- function(model, x_raw){\n","  # Model prediction function: predicts premiums based on the pricing model.\n","\n","  # This function outputs the prices that will be offered to the contracts in X_raw.\n","  # premium will typically depend on the average claim predicted in \n","  # predict_expected_claim, and will add some pricing strategy on top.\n","\n","  # This is the function used in the average profit leaderboard. Prices output here will\n","  # be used in competition with other models, so feel free to use a pricing strategy.\n","\n","  # Parameters\n","  # ----------\n","  # X_raw : Dataframe, with the columns described in the data dictionary.\n","  # \tEach row is a different contract. This data has not been processed.\n","\n","  # Returns\n","  # -------\n","  # prices: a one-dimensional array of the same length as X_raw, with one\n","  #     price per contract (in same order). These prices must be POSITIVE (>0).\n","\n","\n","  # YOUR CODE HERE ------------------------------------------------------\n","\n","  # x_clean = preprocess_X_data(x_raw)  # preprocess your data before fitting\n","\n","  return(predict_expected_claim(model, x_raw) * 1.1)\n","}\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7lD-nxa08tU","colab":{"base_uri":"https://localhost:8080/","height":189},"executionInfo":{"status":"ok","timestamp":1610486621313,"user_tz":300,"elapsed":601472,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}},"outputId":"567680b3-3ff3-4926-beda-6cca8034a14b"},"source":["prices <- predict_premium(model, Xdata)\n","as.matrix(head(prices))"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["     [,1]   \n","[1,] 149.501\n","[2,] 125.587\n","[3,]  85.415\n","[4,] 121.066\n","[5,]  88.462\n","[6,]  86.427"],"text/latex":"A matrix: 6 √ó 1 of type dbl\n\\begin{tabular}{l}\n\t 149.501\\\\\n\t 125.587\\\\\n\t  85.415\\\\\n\t 121.066\\\\\n\t  88.462\\\\\n\t  86.427\\\\\n\\end{tabular}\n","text/markdown":"\nA matrix: 6 √ó 1 of type dbl\n\n| 149.501 |\n| 125.587 |\n|  85.415 |\n| 121.066 |\n|  88.462 |\n|  86.427 |\n\n","text/html":["<table>\n","<caption>A matrix: 6 √ó 1 of type dbl</caption>\n","<tbody>\n","\t<tr><td>149.501</td></tr>\n","\t<tr><td>125.587</td></tr>\n","\t<tr><td> 85.415</td></tr>\n","\t<tr><td>121.066</td></tr>\n","\t<tr><td> 88.462</td></tr>\n","\t<tr><td> 86.427</td></tr>\n","</tbody>\n","</table>\n"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"QGKrsik_b-w3"},"source":["#### Profit on training data\n","\n","In order for your model to be considered in the profit competition, it needs to make nonnegative profit over its training set. You can check that your model satisfies this condition below:"]},{"cell_type":"code","metadata":{"id":"NPssEcCrb-w3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610486621314,"user_tz":300,"elapsed":601468,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}},"outputId":"b421ea45-31f4-40da-81bd-12a97d7bf930"},"source":["print(paste('Income:', sum(prices)))\n","print(paste('Losses:', sum(ydata)))\n","\n","if (sum(prices) < sum(ydata)) {\n","    print('Your model loses money on the training data! It does not satisfy market rule 1: Non-negative training profit.')\n","    print('This model will be disqualified from the weekly profit leaderboard, but can be submitted for educational purposes to the RMSE leaderboard.')\n","} else {\n","    print('Your model passes the non-negative training profit test!')\n","}"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[1] \"Income: 45016367.242\"\n","[1] \"Losses: 26057988.08\"\n","[1] \"Your model passes the non-negative training profit test!\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FE0vTPmDb-w3"},"source":["# Ready? Submit to AIcrowd üöÄ\n","\n","If you are satisfied with your code, run the code below to send your code to the AICrowd servers for evaluation! This requires the variable `trained_model` to be defined by your previous code.\n","\n","**Make sure you have included all packages needed to run your code in the [_\"Packages\"_](#packages) section.**\n","\n","**NOTE**: If you submit the baseline RMSE model without any change whatsoever, your model will not be entered into the market. "]},{"cell_type":"code","metadata":{"id":"bVSbAI37f7Av","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610486630419,"user_tz":300,"elapsed":610567,"user":{"displayName":"alexlepage007","photoUrl":"","userId":"16491687760320876052"}},"outputId":"bc60264d-0a5b-4322-9f9d-458691983c7a"},"source":["aicrowd_submit(AICROWD_API_KEY)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["üöÄ Preparing to submit...\n","‚öôÔ∏è Collecting the submission code...\n","üíæ Preparing the submission zip file...\n","Verifying API Key...\n","API Key valid\n","Saved API Key successfully!\n","                                          ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ                                           \n","                                          ‚îÇ Successfully submitted! ‚îÇ                                           \n","                                          ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ                                           \n","                                                Important links                                                 \n","‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n","‚îÇ  This submission ‚îÇ https://www.aicrowd.com/challenges/insurance-pricing-game/submissions/114363              ‚îÇ\n","‚îÇ                  ‚îÇ                                                                                           ‚îÇ\n","‚îÇ  All submissions ‚îÇ https://www.aicrowd.com/challenges/insurance-pricing-game/submissions?my_submissions=true ‚îÇ\n","‚îÇ                  ‚îÇ                                                                                           ‚îÇ\n","‚îÇ      Leaderboard ‚îÇ https://www.aicrowd.com/challenges/insurance-pricing-game/leaderboards                    ‚îÇ\n","‚îÇ                  ‚îÇ                                                                                           ‚îÇ\n","‚îÇ Discussion forum ‚îÇ https://discourse.aicrowd.com/c/insurance-pricing-game                                    ‚îÇ\n","‚îÇ                  ‚îÇ                                                                                           ‚îÇ\n","‚îÇ   Challenge page ‚îÇ https://www.aicrowd.com/challenges/insurance-pricing-game                                 ‚îÇ\n","‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"],"name":"stdout"}]}]}